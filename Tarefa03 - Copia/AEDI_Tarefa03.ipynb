{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d0d822-c7c4-4d4f-9452-09f52338619c",
   "metadata": {},
   "source": [
    "# Análise Estatística de Dados e Informações\n",
    "**PPCA/UNB**\n",
    "\n",
    "---\n",
    "\n",
    "**Tarefa 03**  \n",
    "**Professor**: João Gabriel de Moraes Sousa  \n",
    "**Aluna**: Andreia Queiroz Correia Dummar  \n",
    "**Matrícula**: 241134680  \n",
    "**Data da Entrega**: 08/12/2024  \n",
    "**Github**: https://github.com/aqcorreia/AEDI/tree/bb68c12f3e69d6cafe3fd7d6864e38b4c0721182/Tarefa03\n",
    "\n",
    "---\n",
    "\n",
    "**Aplicação**: Análise estatística com ANOVA\n",
    "\n",
    "**Dados**: https://www.kaggle.com/prevek18/ames-housing-dataset\n",
    "- Análise considerou as características: No de quartos, bairros e número de garagens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e73abe-c3ec-4755-a8e8-c21a802f66a3",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f502b2b-e055-40b6-ac36-87fe007bb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas essenciais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelos estatísticos e testes\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import shapiro, levene, bartlett, kstest, boxcox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf1238-0cfc-43ca-931e-836ed34bea3d",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30784f82-91ce-47ee-b1f1-a5bb74888e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_distribuicao_e_boxplot(df, feature, target, figsize_dist=(20, 6), figsize_box=(20, 6), x_rotation=0):\n",
    "    \"\"\"\n",
    "    Gera o gráfico de distribuição, o boxplot e um gráfico de linha para uma característica específica e sua relação com uma variável de destino.\n",
    "    Destaca em laranja os dois boxes com maior dispersão e exibe essas categorias no console.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame contendo os dados.\n",
    "        feature (str): Nome da coluna da característica a ser analisada.\n",
    "        target (str): Nome da variável de destino para o boxplot.\n",
    "        figsize_dist (tuple): Tamanho da figura para o gráfico de distribuição (default: (20, 6)).\n",
    "        figsize_box (tuple): Tamanho da figura para o boxplot (default: (20, 6)).\n",
    "\n",
    "    Retorno:\n",
    "        None: Exibe os gráficos diretamente.\n",
    "    \"\"\"\n",
    "    # Gráfico de distribuição\n",
    "    plt.figure(figsize=figsize_dist)\n",
    "    if df[feature].dtype == 'object':  # Variáveis categóricas\n",
    "        sns.countplot(data=df, x=feature, order=df[feature].value_counts().index)\n",
    "        plt.title(f\"Distribuição de {feature}\", fontsize=14)\n",
    "        plt.xlabel(feature, fontsize=12)\n",
    "        plt.ylabel(\"Frequência\", fontsize=12)\n",
    "    else:  # Variáveis numéricas\n",
    "        sns.histplot(df[feature], kde=True, bins=20, color='green')\n",
    "        plt.title(f\"Distribuição de {feature}\", fontsize=14)\n",
    "        plt.xlabel(feature, fontsize=12)\n",
    "        plt.ylabel(\"Frequência\", fontsize=12)\n",
    "    plt.xticks(rotation=x_rotation)  # Inclinar rótulos do eixo x\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Calcular dispersões\n",
    "    dispersoes = df.groupby(feature)[target].apply(lambda x: x.quantile(0.75) - x.quantile(0.25))\n",
    "    maiores_dispersoes = dispersoes.nlargest(2)\n",
    "\n",
    "    # Printar as features com maior dispersão\n",
    "    print(\"Features com maior dispersão:\")\n",
    "    for idx, dispersao in maiores_dispersoes.items():\n",
    "        print(f\"- {idx}: {dispersao:.2f}\")\n",
    "\n",
    "    # Criar uma coluna auxiliar para destacar as categorias com maior dispersão\n",
    "    df['destaque_dispersao'] = df[feature].apply(lambda x: 'Destaque' if x in maiores_dispersoes.index else 'Normal')\n",
    "\n",
    "    # Gráfico de linha: feature x target\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    if df[feature].dtype == 'object':  # Variáveis categóricas\n",
    "        line_data = df.groupby(feature)[target].mean().reset_index()\n",
    "        sns.lineplot(data=line_data, x=feature, y=target, marker='o')\n",
    "    else:  # Variáveis numéricas\n",
    "        line_data = df[[feature, target]].sort_values(by=feature)\n",
    "        sns.lineplot(data=line_data, x=feature, y=target, marker='o')\n",
    "    plt.title(f\"Relação entre {feature} e {target}\", fontsize=14)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.ylabel(target, fontsize=12)\n",
    "    plt.xticks(rotation=x_rotation)  # Inclinar rótulos do eixo x\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Boxplot com destaque para as maiores dispersões\n",
    "    plt.figure(figsize=figsize_box)\n",
    "    sns.boxplot(\n",
    "        data=df, x=feature, y=target, \n",
    "        order=sorted(df[feature].unique()),  # Ordena alfabeticamente as categorias\n",
    "        hue='destaque_dispersao', \n",
    "        palette={\"Destaque\": \"orange\", \"Normal\": \"blue\"}\n",
    "    )\n",
    "    plt.title(f\"Boxplot de {target} por {feature} (maiores dispersões destacadas)\", fontsize=14)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.ylabel(target, fontsize=12)\n",
    "    plt.xticks(rotation=x_rotation)  # Inclinar rótulos do eixo x\n",
    "    plt.legend(title=\"Destaque\", loc=\"upper right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Remover a coluna auxiliar\n",
    "    df.drop(columns='destaque_dispersao', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30580fa4-f97f-4e55-ad50-038e55d4edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_media_por_grupo_com_quantidade(df, feature, target):\n",
    "    \"\"\"\n",
    "    Calcula a média do target por grupo da feature e adiciona a quantidade de registros por grupo.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame contendo os dados.\n",
    "        feature (str): Nome da feature categórica.\n",
    "        target (str): Nome da variável numérica.\n",
    "\n",
    "    Retorno:\n",
    "        pd.DataFrame: DataFrame com a média e a quantidade de registros por grupo.\n",
    "    \"\"\"\n",
    "    media_por_grupo = df.groupby(feature)[target].agg(['mean', 'count']).reset_index()\n",
    "    media_por_grupo.columns = ['Feature Value', 'Mean SalePrice', 'qtde_registros']\n",
    "    media_por_grupo['Feature'] = feature\n",
    "    return media_por_grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3b82f-0cb2-41f0-aa66-1d9f7a698a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_normalidade(df, col_grupo, col_valor):\n",
    "    \"\"\"\n",
    "    Calcula os testes de normalidade Shapiro-Wilk e Kolmogorov-Smirnov para cada grupo em um DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame contendo todos os registros.\n",
    "        col_grupo (str): Nome da coluna categórica para agrupar os dados.\n",
    "        col_valor (str): Nome da coluna numérica para verificar a normalidade.\n",
    "\n",
    "    Retorno:\n",
    "        pd.DataFrame: DataFrame com os resultados dos testes de normalidade.\n",
    "    \"\"\"\n",
    "    # Lista para armazenar os resultados\n",
    "    normalidade_resultados = []\n",
    "\n",
    "    # Agrupar os dados pelo valor da coluna categórica\n",
    "    grupos = df.groupby(col_grupo)\n",
    "\n",
    "    # Iterar sobre os grupos\n",
    "    for grupo, dados in grupos:\n",
    "        qtde_registros = len(dados[col_valor])  # Quantidade de registros no grupo\n",
    "\n",
    "        if qtde_registros >= 3:  # Apenas realizar os testes se houver pelo menos 3 registros\n",
    "            # Teste Shapiro-Wilk\n",
    "            stat_sw, p_value_sw = shapiro(dados[col_valor])\n",
    "\n",
    "            # Teste Kolmogorov-Smirnov\n",
    "            stat_ks, p_value_ks = kstest(\n",
    "                (dados[col_valor] - dados[col_valor].mean()) / dados[col_valor].std(),\n",
    "                cdf='norm'\n",
    "            )\n",
    "\n",
    "            # Adicionar resultados ao DataFrame\n",
    "            normalidade_resultados.append({\n",
    "                'Grupo': grupo,\n",
    "                'Shapiro-Wilk p-value': p_value_sw,\n",
    "                'Kolmogorov-Smirnov p-value': p_value_ks,\n",
    "                'Normal Distribution (Shapiro-Wilk)': 'Sim' if p_value_sw >= 0.05 else 'Não',\n",
    "                'Normal Distribution (K-S)': 'Sim' if p_value_ks >= 0.05 else 'Não',\n",
    "                'Quantidade de Registros': qtde_registros\n",
    "            })\n",
    "        else:\n",
    "            # Caso o grupo não tenha dados suficientes para os testes\n",
    "            normalidade_resultados.append({\n",
    "                'Grupo': grupo,\n",
    "                'Shapiro-Wilk p-value': None,\n",
    "                'Kolmogorov-Smirnov p-value': None,\n",
    "                'Normal Distribution (Shapiro-Wilk)': 'Amostra insuficiente',\n",
    "                'Normal Distribution (K-S)': 'Amostra insuficiente',\n",
    "                'Quantidade de Registros': qtde_registros\n",
    "            })\n",
    "\n",
    "    # Criar e retornar o DataFrame com os resultados\n",
    "    return pd.DataFrame(normalidade_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ee68e-eb42-4d15-9b0b-0797cb9518c3",
   "metadata": {},
   "source": [
    "## 1) Leitura do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605891ab-b38a-4e9f-b286-5c7cda4d5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho do arquivo CSV no subdiretório 'dados'\n",
    "file_path = './dados/AmesHousing.csv'\n",
    "\n",
    "# Leitura do arquivo CSV\n",
    "df_AmesHousing = pd.read_csv(file_path)\n",
    "\n",
    "df_AmesHousing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548f6b9-c008-408c-b340-2d53ed1f2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AmesHousing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268d91f-d47b-45e0-821f-36e7639b1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as colunas necessárias\n",
    "df_AmesHousing = df_AmesHousing[['SalePrice', 'Bedroom AbvGr', 'Garage Cars', 'Neighborhood']]\n",
    "\n",
    "# Renomear colunas para facilitar a manipulação\n",
    "df_AmesHousing.columns = ['SalePrice', 'Bedrooms', 'Garage', 'Neighborhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142101a7-44d6-4a12-b507-ceb279e9cae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b003cd-5107-4b25-947b-774dc7213ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AmesHousing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0cf14-7d1c-4058-bd1e-8abd54e93144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AmesHousing.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f528ac2-7a33-4c70-a38a-0a2a9ebd60e7",
   "metadata": {},
   "source": [
    "# 2) Análise Exploratória\n",
    "\n",
    "**2.1) Bedrooms**\n",
    "\n",
    "- **Média**: 2,85 quartos;\n",
    "- **Mediana**: 3 quartos, muito próxima da média, sugerindo uma distribuição aproximadamente simétrica para a variável `Bedrooms`;\n",
    "- A distribuição está concentrada principalmente entre **2 e 3 quartos**, conforme observado no gráfico de distribuição;\n",
    "- Há **8 imóveis** com **0 quartos**, o que pode representar outliers ou espaços não configurados como quartos tradicionais (ex.: estúdios ou imóveis comerciais);\n",
    "- No **gráfico \"Relação entre Bedrooms e SalePrice\"**, percebe-se que o preço de venda tende a aumentar conforme o número de quartos. Contudo, há uma grande variabilidade de preços dentro de cada número de quartos, o que indica que fatores adicionais (como localização, tamanho geral do imóvel e características internas) influenciam mais significativamente no preço de venda do que apenas o número de quartos;\n",
    "- No **gráfico \"Boxplot do Preço de Venda por Número de Quartos\"**, observa-se uma quantidade significativa de outliers especialmente em imóveis com **4 ou mais quartos**. Isso reforça a ideia de que os preços para imóveis maiores podem variar amplamente, possivelmente devido a características exclusivas;\n",
    "- Apesar de haver algumas amostras de imóveis com **7 ou mais quartos**, o pequeno número de observações limita a análise da dispersão ou tendências consistentes para essa categoria.\n",
    "\n",
    "\n",
    "\n",
    "**2.2) Número de garagens**\n",
    "- Média de 1,7668 garagens;\n",
    "- Maioria das casas possui de 1 a 2 vagas na garagem;\n",
    "- No gráfico de comparação do número de vagas e o preço, **gráfico \"Relação entre Garage e SalePrice\"**, observa-se uma influência positiva do número de vagas no preço até 3 vagas, acima de 3 vagas há poucos imóveis;\n",
    "- No **gráfico \"Boxplot do Preço de Venda por Número de Vagas na Garagem\"**, observa-se uma maior dispersão em 3 vagas, mas nesse caso, há uma menor frequência de imóveis.\n",
    "\n",
    "**2.3) Neighborhood**\n",
    "- **Variável categórica**, no total de 28 bairros distintos;\n",
    "- Não há nenhum imóvel sem bairro;\n",
    "- No **gráfico de \"Distribuição de Neighbouhood\"** é possível obsevar que os bairros possum frequências bastante variadas;\n",
    "- Na comparação dos bairros com o preço, **gráfico \"Relação entre Neighborhood e SalePrice\"**, observa-se a influência do bairro nos preços. Alguns apresentam alta dispersão, como o StoneBr, e outros mais homogêneos como o NPkVill;\n",
    "- Os preços mais altos, observado pelo valor da media no gráfica de Relação entre Neighborhood e SalePrice\", são NridgHT e StoneBr, e os com preços mais baixos são IDOTRR e MeadowV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9705670-44d0-4f59-a021-ad6b38db2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo estatístico das variáveis numéricas\n",
    "print(\"\\nResumo estatístico das variáveis:\")\n",
    "print(df_AmesHousing.describe())\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\nValores nulos por coluna:\")\n",
    "print(df_AmesHousing.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7c923-c185-49f2-954d-9a2fe4ac1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os valores distintos da coluna 'Neighborhood'\n",
    "distinct_neighborhoods = df_AmesHousing['Neighborhood'].unique()\n",
    "print(\"Bairros distintos:\")\n",
    "print(distinct_neighborhoods)\n",
    "\n",
    "# Contar a quantidade de bairros distintos\n",
    "num_neighborhoods = df_AmesHousing['Neighborhood'].nunique()\n",
    "print(f\"Quantidade de bairros distintos: {num_neighborhoods}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433fee9c-9688-4e00-bb0e-e76d0d6e4b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento dos dados\n",
    "\n",
    "# Remove a linha nula existente\n",
    "df_AmesHousing = df_AmesHousing.dropna()\n",
    "\n",
    "df_AmesHousing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f16761-19b9-4260-af9d-7e9ef550fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analisar_distribuicao_e_boxplot(df_AmesHousing, 'Bedrooms' , 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783fd66d-0e57-432f-a7b4-2eac3993a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar a quantidade de imóveis com 0 quartos\n",
    "imoveis_com_0_quartos = df_AmesHousing[df_AmesHousing['Bedrooms'] == 0].shape[0]\n",
    "\n",
    "print(f\"Quantidade de imóveis com 0 quartos: {imoveis_com_0_quartos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165872a3-06d0-4fcd-a637-95a94e2b2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "analisar_distribuicao_e_boxplot(df_AmesHousing, 'Garage' , 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b4a0d-28bc-4ca7-ab29-a0b74d0fdf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analisar_distribuicao_e_boxplot(df_AmesHousing, 'Neighborhood' , 'SalePrice', x_rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8429a6-96c7-4658-b694-e1f9268ee8b9",
   "metadata": {},
   "source": [
    "# 2) Análise estatística ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff86615-08bb-487b-a148-b664b447b449",
   "metadata": {},
   "source": [
    "A **Análise de Variância (ANOVA)** será utilizada para investigar se as médias de variáveis relacionadas ao preço de venda de imóveis (**`SalePrice`**) são significativamente diferentes em relação a determinadas categorias no dataset **Ames Housing**. O ANOVA avalia a variância **entre os grupos** e a variância **dentro dos grupos** para determinar se as diferenças observadas entre as médias são estatisticamente significativas.\n",
    "\n",
    "## Hipóteses do Teste ANOVA\n",
    "\n",
    "O teste ANOVA trabalha com as seguintes hipóteses:\n",
    "\n",
    "- **Hipótese Nula (\\(H_0\\))**: As médias de **`SalePrice`** são iguais entre os grupos definidos pelas variáveis categóricas analisadas.\n",
    "  $$\n",
    "  H_0 : \\mu_1 = \\mu_2 = \\mu_3 = \\dots = \\mu_n\n",
    "  $$\n",
    "\n",
    "- **Hipótese Alternativa (\\(H_A\\))**: Pelo menos um grupo tem média de **`SalePrice`** diferente.\n",
    "  $$\n",
    "  H_A : \\exists \\, i, j \\, | \\, \\mu_i \\neq \\mu_j \\, (i \\neq j)\n",
    "  $$\n",
    "\n",
    "## Variáveis Selecionadas\n",
    "\n",
    "As variáveis do dataset **Ames Housing** consideradas para a análise são:\n",
    "\n",
    "- **`SalePrice`** (variável dependente): Representa o preço de venda dos imóveis.\n",
    "- **`Bedroom AbvGr`** (variável independente): Número de quartos acima do nível do solo.\n",
    "- **`Garage Cars`** (variável independente): Capacidade da garagem em termos de número de carros.\n",
    "- **`Neighborhood`** (variável independente): Bairro onde o imóvel está localizado.\n",
    "\n",
    "## Suposições do ANOVA\n",
    "\n",
    "Para realizar o ANOVA corretamente, é necessário verificar as seguintes condições:\n",
    "\n",
    "1. **Independência das Observações**:\n",
    "   - Os preços de venda dos imóveis (**`SalePrice`**) devem ser independentes para cada nível das variáveis categóricas. No contexto do **Ames Housing**, pode-se assumir que os registros de diferentes propriedades são independentes.\n",
    "\n",
    "2. **Normalidade**:\n",
    "   - A distribuição de **`SalePrice`** para cada nível das variáveis categóricas (**`Bedroom AbvGr`**, **`Garage Cars`**, e **`Neighborhood`**) deve seguir uma distribuição normal.\n",
    "   - Para verificar essa suposição, utilizaremos:\n",
    "     - **Teste de Shapiro-Wilk**:\n",
    "       - \\( p >= 0.05 \\): Distribuição normal (não rejeitamos a hipótese nula).\n",
    "       - \\( p < 0.05 \\): Distribuição não normal (rejeitamos a hipótese nula).\n",
    "     - **Teste de Kolmogorov-Smirnov**:\n",
    "       - \\( p >= 0.05 \\): Distribuição normal (não rejeitamos a hipótese nula).\n",
    "       - \\( p < 0.05 \\): Distribuição não normal (rejeitamos a hipótese nula).\n",
    "\n",
    "3. **Homogeneidade de Variâncias**:\n",
    "   - As variâncias de **`SalePrice`** entre os grupos devem ser iguais (homocedasticidade).\n",
    "   - Essa condição pode ser avaliada com:\n",
    "     - **Teste de Levene**: Sensível a desvios de homogeneidade.\n",
    "     - **Teste de Bartlett**: Verifica igualdade das variâncias assumindo normalidade.\n",
    "\n",
    "## Objetivo da Análise\n",
    "\n",
    "O objetivo do teste ANOVA neste dataset é verificar se:\n",
    "\n",
    "1. O número de quartos (**`Bedroom AbvGr`**) impacta significativamente o preço de venda (**`SalePrice`**).\n",
    "2. A capacidade da garagem (**`Garage Cars`**) influencia o preço de venda (**`SalePrice`**).\n",
    "3. Os preços de venda (**`SalePrice`**) variam significativamente entre os bairros (**`Neighborhood`**).\n",
    "\n",
    "## Etapas do Procedimento\n",
    "\n",
    "1. **Preparação dos Dados**:\n",
    "   - Dividir o dataset em grupos com base nos valores únicos de cada variável categórica (**`Bedroom AbvGr`**, **`Garage Cars`**, e **`Neighborhood`**).\n",
    "\n",
    "2. **Verificação das Suposições**:\n",
    "   - **Independência**: Confirmar que os registros no dataset são independentes.\n",
    "   - **Normalidade**: Testar a normalidade de **`SalePrice`** para cada grupo.\n",
    "   - **Homogeneidade de Variâncias**: Confirmar se as variâncias de **`SalePrice`** são homogêneas entre os grupos.\n",
    "\n",
    "3. **Execução do Teste ANOVA**:\n",
    "   - Aplicar o teste ANOVA para verificar se as diferenças nas médias de **`SalePrice`** entre os grupos são significativas.\n",
    "\n",
    "4. **Interpretação dos Resultados**:\n",
    "   - Se o valor-p do teste ANOVA for menor que 0.05 (\\(p < 0.05\\)), rejeitamos \\(H_0\\) e concluímos que existe uma diferença significativa entre os grupos.\n",
    "   - Caso contrário (\\(p \\geq 0.05\\)), não há evidências estatísticas para rejeitar \\(H_0\\), e as médias podem ser consideradas iguais.\n",
    "\n",
    "---\n",
    "\n",
    "Este procedimento permitirá avaliar o impacto de características como o número de quartos, a capacidade da garagem e a localização no preço de venda dos imóveis no dataset **Ames Housing**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12048e20-7f42-4450-9856-74a8c00eef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar para cada feature\n",
    "df_bedrooms = calcular_media_por_grupo_com_quantidade(df_AmesHousing, 'Bedrooms', 'SalePrice')\n",
    "df_garage = calcular_media_por_grupo_com_quantidade(df_AmesHousing, 'Garage', 'SalePrice')\n",
    "df_neighborhood = calcular_media_por_grupo_com_quantidade(df_AmesHousing, 'Neighborhood', 'SalePrice')\n",
    "\n",
    "# Combinar os resultados em um único DataFrame\n",
    "df_neighborhood_media = pd.concat([df_bedrooms, df_garage, df_neighborhood], ignore_index=True)\n",
    "\n",
    "# Filtrar o DataFrame para grupos com menos de 4 registros\n",
    "df_filtrado = df_neighborhood_media[df_neighborhood_media['qtde_registros'] < 4]\n",
    "\n",
    "# Exibir o DataFrame filtrado\n",
    "df_filtrado.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10f4ebc-c306-4167-a604-b02d75f7d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta colunas que contenham no grupo menos de 4 registros, para isso grupos serão agrupados\n",
    "\n",
    "# Criar uma nova coluna 'Bedrooms_2' com as condições especificadas\n",
    "df_AmesHousing['Bedrooms_2'] = df_AmesHousing['Bedrooms'].apply(\n",
    "    lambda x: '2A' if x <= 2 else ('4A' if x >= 4 else x)\n",
    ")\n",
    "\n",
    "# Criar uma nova coluna 'Garage_2' com as condições especificadas\n",
    "df_AmesHousing['Garage_2'] = df_AmesHousing['Garage'].apply(\n",
    "    lambda x: '1A' if x <= 1 else ('3A' if x >= 3 else x)\n",
    ")\n",
    "\n",
    "# Criar a coluna 'Neighborhood_2' com base nos valores de 'Neighborhood'\n",
    "df_AmesHousing['Neighborhood_2'] = df_AmesHousing['Neighborhood'].apply(\n",
    "    lambda x: 'Grp_LGGBN' if x in ['Landmrk', 'GrnHill', 'Greens', 'Blueste', 'NPkVill'] else x\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd55d63-5f01-46f7-8379-b63ebeba6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar para cada feature\n",
    "df_bedrooms = calcular_media_por_grupo_com_quantidade(df_AmesHousing, 'Bedrooms_2', 'SalePrice')\n",
    "df_garage = calcular_media_por_grupo_com_quantidade(df_AmesHousing, 'Garage_2', 'SalePrice')\n",
    "df_neighborhood = calcular_media_por_grupo_com_quantidade(df_AmesHousing, 'Neighborhood_2', 'SalePrice')\n",
    "\n",
    "# Combinar os resultados em um único DataFrame\n",
    "df_neighborhood_media = pd.concat([df_bedrooms, df_garage, df_neighborhood], ignore_index=True)\n",
    "\n",
    "# Filtrar o DataFrame para grupos com menos de 4 registros\n",
    "df_filtrado = df_neighborhood_media[df_neighborhood_media['qtde_registros'] < 4]\n",
    "\n",
    "# Exibir o DataFrame filtrado\n",
    "df_filtrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf199b-112b-490d-a153-e3110c86e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir o DataFrame consolidado\n",
    "df_neighborhood_media.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e6059-e5e8-4996-a220-a6c32d22d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia a normalidade de Bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1993196-b590-4c22-9bc8-6797d12b8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = calcular_normalidade(df_AmesHousing, col_grupo='Bedrooms_2', col_valor='SalePrice')\n",
    "\n",
    "df_normalidade_nao = df_resultados[df_resultados['Normal Distribution (K-S)'] != 'Sim']\n",
    "df_normalidade_nao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94244916-1b2a-4382-8df1-860776ad5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar novas colunas no DataFrame com as transformações logarítmica e de raiz quadrada\n",
    "df_AmesHousing['SalePrice_log'] = df_AmesHousing['SalePrice'].apply(lambda x: np.log(x) if x > 0 else None)\n",
    "df_AmesHousing['SalePrice_sqrt'] = df_AmesHousing['SalePrice'].apply(lambda x: np.sqrt(x) if x >= 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be645e41-6ff0-42cc-8c16-596df78b91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = calcular_normalidade(df_AmesHousing, col_grupo='Bedrooms', col_valor='SalePrice')\n",
    "\n",
    "df_normalidade_nao = df_resultados[df_resultados['Normal Distribution (K-S)'] != 'Sim']\n",
    "df_normalidade_nao.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a11bc-f072-4ba7-bd35-f7ce620b6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Criar um DataFrame para armazenar os resultados do teste de normalidade\n",
    "normalidade_resultados = []\n",
    "\n",
    "# Definir as features categóricas a serem analisadas\n",
    "features = ['Neighborhood', 'Bedrooms', 'Garage']  # Substituir pelos nomes das colunas reais\n",
    "\n",
    "# Iterar sobre as features e testar normalidade em cada grupo\n",
    "for feature in features:\n",
    "    grupos = df_AmesHousing.groupby(feature)\n",
    "    for grupo, dados in grupos:\n",
    "        qtde_registros = len(dados['SalePrice'])  # Quantidade de registros no grupo\n",
    "        if qtde_registros >= 3:  # Garantir que o grupo tem dados suficientes\n",
    "            stat, p_value = shapiro(dados['SalePrice'])\n",
    "            normalidade_resultados.append({\n",
    "                'Feature': feature,\n",
    "                'Feature Value': grupo,\n",
    "                'Shapiro-Wilk p-value': p_value,\n",
    "                'Quantidade de Registros': qtde_registros,\n",
    "                'Normal Distribution': 'Sim' if p_value >= 0.05 else 'Não'\n",
    "                \n",
    "            })\n",
    "        else:\n",
    "            # Caso o grupo não tenha dados suficientes para o teste\n",
    "            normalidade_resultados.append({\n",
    "                'Feature': feature,\n",
    "                'Feature Value': grupo,\n",
    "                'Shapiro-Wilk p-value': None,\n",
    "                'Quantidade de Registros': qtde_registros,\n",
    "                'Normal Distribution': 'Amostra insuficiente'\n",
    "            })\n",
    "\n",
    "# Criar o DataFrame com os resultados\n",
    "df_normalidade = pd.DataFrame(normalidade_resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e6512-be03-4fb2-ab2d-1f9faa25d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar os resultados onde a distribuição não é normal\n",
    "df_normalidade_nao = df_normalidade[df_normalidade['Normal Distribution'] == 'Não']\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"Grupos que não seguem a normalidade:\")\n",
    "df_normalidade_nao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f70dc-b3ce-480a-af7f-bf2b19c9e19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
