{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Estatística de Dados e Informações\n",
    "**PPCA/UNB**\n",
    "\n",
    "---\n",
    "\n",
    "**Tarefa 04**  \n",
    "**Professor**: João Gabriel de Moraes Sousa  \n",
    "**Aluna**: Andreia Queiroz Correia Dummar  \n",
    "**Matrícula**: 241134680  \n",
    "**Data da Entrega**: 12/01/2025  \n",
    "**Github**: https://github.com/aqcorreia/AEDI/tree/3e6a999ac003892ea0a9a114b694eed1b5fca9dd/Tarefa05\n",
    "\n",
    "---\n",
    "\n",
    "**Aplicação**: Regressão Logística\n",
    "\n",
    "**Dados**: Retenção de Clientes em Unidades Bancárias (https://www.kaggle.com/code/kmalit/bank-customer-churn-prediction/input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bibliotecas para manipulação de dados ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Bibliotecas para visualização ---\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# --- Bibliotecas para pré-processamento ---\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# --- Bibliotecas para modelagem e validação ---\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "# --- Bibliotecas para análise estatística ---\n",
    "from statsmodels.api import Logit, add_constant\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# --- Bibliotecas para balanceamento de classes ---\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Leitura do arquivo Churn_Modelling.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio = './dados'\n",
    "churn_modelling_data = pd.read_csv(f'{diretorio}/Churn_Modelling.csv', delimiter=',')\n",
    "\n",
    "churn_modelling_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_modelling_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_modelling_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_modelling_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Modelo de regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) Identificando as variáveis mais significativas para o modelo de regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as colunas relevantes\n",
    "X = churn_modelling_data[['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', \n",
    "        'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']]\n",
    "y = churn_modelling_data['Exited']\n",
    "\n",
    "# Definir variáveis categóricas e numéricas\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', \n",
    "                      'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "# Criar transformadores para numéricas e categóricas\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Preencher valores ausentes com a média\n",
    "    ('scaler', StandardScaler())  # Escalar variáveis numéricas\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Preencher valores ausentes com a moda\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Codificar variáveis categóricas\n",
    "])\n",
    "\n",
    "# Combinar os transformadores em um ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Criar pipeline completo com preprocessador e modelo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Dividir os dados em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Avaliar o modelo\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # Imprimir resultados\n",
    "# print(\"Acurácia do modelo:\", accuracy)\n",
    "# print(\"Matriz de Confusão:\\n\", conf_matrix)\n",
    "# print(\"Relatório de Classificação:\\n\", class_report)\n",
    "\n",
    "# Obter os coeficientes do modelo\n",
    "classifier = pipeline.named_steps['classifier']\n",
    "print(\"Coeficientes do modelo (variáveis numéricas):\\n\", classifier.coef_)\n",
    "print(\"Intercepto do modelo:\\n\", classifier.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Análise\n",
    "1. **CreditScore (\\(-0.0676\\))**: Um maior crédito reduz levemente a probabilidade de saída.  \n",
    "2. **Age (\\(0.7546\\))**: Clientes mais velhos têm maior probabilidade de sair.  \n",
    "3. **Tenure (\\(-0.0428\\))**: Um tempo maior no banco reduz ligeiramente a probabilidade de saída.  \n",
    "4. **Balance (\\(0.1611\\))**: Um saldo maior está associado a uma probabilidade levemente maior de saída.  \n",
    "5. **NumOfProducts (\\(-0.0604\\))**: Um maior número de produtos reduz moderadamente a chance de saída.  \n",
    "6. **HasCrCard (\\(-0.0103\\))**: Ter cartão de crédito não influencia significativamente na saída.  \n",
    "7. **IsActiveMember (\\(-0.5337\\))**: Ser um membro ativo reduz consideravelmente a probabilidade de saída.  \n",
    "8. **EstimatedSalary (\\(0.0157\\))**: O salário estimado tem impacto irrelevante na saída.  \n",
    "\n",
    "---\n",
    "\n",
    "##### Diferença entre os Impactos de `CreditScore` e `NumOfProducts`\n",
    "Embora os coeficientes de `CreditScore` (\\(-0.0676\\)) e `NumOfProducts` (\\(-0.0604\\)) sejam próximos, o impacto de cada variável no modelo é percebido de forma diferente devido a dois fatores principais:\n",
    "\n",
    "1. **Escala das Variáveis**:\n",
    "   - **`CreditScore`**: Varia em uma escala ampla (e.g., 300 a 850), de modo que o impacto de pequenas mudanças no coeficiente é diluído.  \n",
    "   - **`NumOfProducts`**: Geralmente varia em uma escala pequena (e.g., 1 a 4), então cada unidade adicional gera um impacto mais evidente.\n",
    "\n",
    "2. **Interpretação Contextual**:\n",
    "   - **`CreditScore`**: É uma métrica contínua, cuja influência no comportamento do cliente é mais difusa e menos diretamente relacionada à decisão de saída.  \n",
    "   - **`NumOfProducts`**: Reflete o envolvimento do cliente com o banco; mais produtos indicam maior fidelidade, reduzindo a probabilidade de saída de forma mais significativa.\n",
    "\n",
    "---\n",
    "\n",
    "##### Conclusão\n",
    "Os fatores mais importantes são **Age (aumenta a saída)** e **IsActiveMember (reduz a saída)**, seguidos por **Balance** e **NumOfProducts**s. A diferença na escala e no contexto das variáveis explica por que `NumOfProducts` apresenta um impacto moderado, enquanto `CreditScore` reduz levemente a probabilidade de saída.\n",
    "\n",
    "Com isso, será gerado o modelo considerando as variáveis: **Age, IsActiveMember, Balance e NumOfProducts**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2) Gerando o modelo com as variáveis mais significativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as colunas relevantes\n",
    "X = churn_modelling_data[['Age', 'IsActiveMember', 'Balance', 'NumOfProducts']]\n",
    "y = churn_modelling_data['Exited']\n",
    "\n",
    "# Tratar valores ausentes, se houver\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Dividir os dados em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instanciar o modelo de regressão logística\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"Acurácia do modelo:\", accuracy)\n",
    "print(\"Matriz de Confusão:\\n\", conf_matrix)\n",
    "print(\"Relatório de Classificação:\\n\", class_report)\n",
    "\n",
    "# Exibir os coeficientes do modelo\n",
    "print(\"Coeficientes do modelo:\", model.coef_)\n",
    "print(\"Intercepto do modelo:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Análise do Modelo de Regressão Logística\n",
    "\n",
    "O modelo apresenta uma acurácia de 81% e um pseudo R² de 0.1259, indicando que explica cerca de 12.59% da variação na variável dependente. A matriz de confusão destaca o excelente desempenho na classe 0 (\\(Recall = 97\\%\\)), enquanto o desempenho na classe 1 é insatisfatório (\\(Recall = 15\\%\\)).\n",
    "\n",
    "Os coeficientes mostram que a variável IsActiveMember tem o maior impacto negativo -1.07409821, Age (0.07187654) e NumOfProducts (-0.03150081) possuem impactos pequenos, e Balance (0.00000483) tem impacto insignificante.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3) Validando os pressupostos da regressão logística para o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.1) Linearidade entre as variáveis independentes e o logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar variáveis independentes e dependente\n",
    "X = churn_modelling_data[['Age', 'IsActiveMember', 'Balance', 'NumOfProducts']]\n",
    "y = churn_modelling_data['Exited']\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar as variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "# Adicionar constante para statsmodels\n",
    "X_train_scaled = add_constant(X_train_scaled)\n",
    "\n",
    "# Garantir alinhamento dos índices entre X e y\n",
    "X_train_scaled = X_train_scaled.loc[y_train.index]\n",
    "\n",
    "# Ajustar o modelo logístico com statsmodels\n",
    "logit_model = Logit(y_train, X_train_scaled)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Obter os log-odds para verificar linearidade\n",
    "predicted_logit = result.predict(X_train_scaled)\n",
    "\n",
    "# Verificar a relação linear entre cada variável e o logit\n",
    "for col in X_train_scaled.columns[1:]:  # Exclui a constante\n",
    "    plt.figure()\n",
    "    plt.scatter(X_train_scaled[col], predicted_logit, alpha=0.5)\n",
    "    plt.title(f\"Linearidade entre {col} e o logit\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Logit\")\n",
    "    plt.show()\n",
    "\n",
    "# Exibir resumo do modelo\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2) Multicolinearidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "def calculate_vif(data):\n",
    "    \"\"\"\n",
    "    Calcula o Variance Inflation Factor (VIF) para avaliar multicolinearidade.\n",
    "    \n",
    "    Parâmetros:\n",
    "        data (DataFrame): DataFrame contendo as variáveis independentes.\n",
    "        \n",
    "    Retorna:\n",
    "        DataFrame: Contém o nome das variáveis e seus respectivos VIFs.\n",
    "    \"\"\"\n",
    "    # Adiciona uma constante ao conjunto de dados para o cálculo do VIF\n",
    "    data_with_const = add_constant(data)\n",
    "    \n",
    "    # Calcula o VIF para cada variável\n",
    "    vif_data = pd.DataFrame({\n",
    "        'Variable': data_with_const.columns,\n",
    "        'VIF': [variance_inflation_factor(data_with_const.values, i) \n",
    "                for i in range(data_with_const.shape[1])]\n",
    "    })\n",
    "    \n",
    "    # Remove a constante da tabela final\n",
    "    vif_data = vif_data[vif_data['Variable'] != 'const']\n",
    "    \n",
    "    return vif_data\n",
    "\n",
    "# Exemplo de uso\n",
    "# Suponha que X_train_scaled seja o DataFrame das variáveis independentes normalizadas\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=['Age', 'IsActiveMember', 'Balance', 'NumOfProducts'])\n",
    "\n",
    "# Calcula os VIFs\n",
    "vif_result = calculate_vif(X_train_df)\n",
    "\n",
    "# Exibe os resultados\n",
    "print(\"Variance Inflation Factor (VIF):\")\n",
    "print(vif_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3) Avaliando o desbalanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_desbalanceamento(y):\n",
    "    \"\"\"\n",
    "    Verifica o desbalanceamento de classes em uma variável dependente e plota a distribuição.\n",
    "\n",
    "    Parâmetros:\n",
    "        y (pd.Series ou np.array): Variável dependente contendo as classes.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Frequência absoluta e relativa de cada classe.\n",
    "    \"\"\"\n",
    "    # Calcula a frequência absoluta e relativa\n",
    "    freq_absoluta = pd.Series(y).value_counts()\n",
    "    freq_relativa = pd.Series(y).value_counts(normalize=True) * 100\n",
    "\n",
    "    # Exibe os resultados\n",
    "    print(\"Frequência Absoluta:\")\n",
    "    print(freq_absoluta)\n",
    "    print(\"\\nFrequência Relativa (%):\")\n",
    "    print(freq_relativa)\n",
    "\n",
    "    # Plotando a distribuição\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    freq_absoluta.plot(kind='bar', color=['skyblue', 'orange'])\n",
    "    plt.title(\"Distribuição das Classes\")\n",
    "    plt.xlabel(\"Classe\")\n",
    "    plt.ylabel(\"Frequência\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.show()\n",
    "\n",
    "    return {\"Frequência Absoluta\": freq_absoluta, \"Frequência Relativa (%)\": freq_relativa}\n",
    "\n",
    "# Exemplo de uso\n",
    "# Suponha que y seja a variável dependente contendo as classes\n",
    "y_train_series = pd.Series(y_train)  # Transformando y_train em série caso necessário\n",
    "resultado = verificar_desbalanceamento(y_train_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Análise dos pressupostos da regressão logística (linearidade entre as variáveis independentes e o logit, ausência de multicolinearidade e balanceamento da variável dependente (Exited)\n",
    "\n",
    "#### Linearidade entre as variáveis independentes e o logit\n",
    "\n",
    "O modelo apresenta um **pseudo R² de 0.1259**, indicando que o modelo explica cerca de 12.59% da variação na variável dependente (\\(Exited\\)). O pseudo \\(R^2\\) é uma medida de ajuste específica para modelos de classificação, que avalia a proporção da variação explicada em relação a um modelo nulo (sem preditores).\n",
    "\n",
    "As variáveis **`Age`** (\\(coef = 0.7566\\)), **`IsActiveMember`** (\\(coef = -0.5390\\)) e **`Balance`** (\\(coef = 0.3015\\)) são estatisticamente significativas (\\(P < 0.05\\)), impactando a probabilidade de saída. Já **`NumOfProducts`** não é relevante (\\(P = 0.540\\)).\n",
    "\n",
    "#### Multicolinearidade\n",
    "\n",
    "Os valores de **Variance Inflation Factor (VIF)** indicam que todas as variáveis possuem VIF próximo de 1, sugerindo **baixa correlação** entre as variáveis independentes. Isso confirma que **não há multicolinearidade significativa** no modelo, e todas as variáveis podem ser mantidas. O modelo é adequado nesse aspecto.\n",
    "\n",
    "#### Balanceamento da variável dependente (Exited)\n",
    "\n",
    "O conjunto de dados apresenta um **desbalanceamento**, com 79.45% das observações na classe 0 (\\(Exited = 0\\)) e apenas 20.55% na classe 1 (\\(Exited = 1\\)). Esse desbalanceamento pode dificultar a detecção da classe minoritária.\n",
    "\n",
    "#### Conclusão\n",
    "\n",
    "Será realizado um balanceamento de classes com SMOTE e será removida a variável NumOfProducts do modelo\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4) Executando o modelo após o balanceamento com SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados simulados (substituir com churn_modelling_data)\n",
    "# X contém as variáveis independentes, y é a variável dependente\n",
    "X = churn_modelling_data[['Age', 'IsActiveMember', 'Balance']]\n",
    "y = churn_modelling_data['Exited']\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Normalizando as variáveis independentes\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Aplicando SMOTE para balancear as classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# **Modelo 1: Random Forest**\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced')\n",
    "rf_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Avaliando o Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test_scaled)\n",
    "rf_y_prob = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Random Forest - Confusion Matrix:\\n\", confusion_matrix(y_test, rf_y_pred))\n",
    "print(\"\\nRandom Forest - Classification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
    "print(\"Random Forest - AUC:\", roc_auc_score(y_test, rf_y_prob))\n",
    "\n",
    "# **Modelo 2: Gradient Boosting**\n",
    "gb_model = GradientBoostingClassifier(random_state=42, n_estimators=100)\n",
    "gb_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Avaliando o Gradient Boosting\n",
    "gb_y_pred = gb_model.predict(X_test_scaled)\n",
    "gb_y_prob = gb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nGradient Boosting - Confusion Matrix:\\n\", confusion_matrix(y_test, gb_y_pred))\n",
    "print(\"\\nGradient Boosting - Classification Report:\\n\", classification_report(y_test, gb_y_pred))\n",
    "print(\"Gradient Boosting - AUC:\", roc_auc_score(y_test, gb_y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar gráficos 3D de antes e depois do balanceamento\n",
    "def plot_3d_before_after(X_before, y_before, X_after, y_after):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # Gráfico antes do balanceamento\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    scatter1 = ax1.scatter(\n",
    "        X_before[:, 0], X_before[:, 1], X_before[:, 2],\n",
    "        c=y_before, cmap='viridis', s=10\n",
    "    )\n",
    "    ax1.set_title(\"Antes do Balanceamento\")\n",
    "    ax1.set_xlabel(\"Age\")\n",
    "    ax1.set_ylabel(\"IsActiveMember\")\n",
    "    ax1.set_zlabel(\"NumOfProducts\")\n",
    "    legend1 = ax1.legend(*scatter1.legend_elements(), title=\"Exited\")\n",
    "    ax1.add_artist(legend1)\n",
    "\n",
    "    # Gráfico depois do balanceamento\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    scatter2 = ax2.scatter(\n",
    "        X_after[:, 0], X_after[:, 1], X_after[:, 2],\n",
    "        c=y_after, cmap='viridis', s=10\n",
    "    )\n",
    "    ax2.set_title(\"Depois do Balanceamento\")\n",
    "    ax2.set_xlabel(\"Age\")\n",
    "    ax2.set_ylabel(\"IsActiveMember\")\n",
    "    ax2.set_zlabel(\"NumOfProducts\")\n",
    "    legend2 = ax2.legend(*scatter2.legend_elements(), title=\"Exited\")\n",
    "    ax2.add_artist(legend2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Selecionando as variáveis para o gráfico\n",
    "X_before = X_train_scaled[:, :3]  # Variáveis independentes antes do balanceamento\n",
    "y_before = y_train.values         # Variável dependente antes do balanceamento\n",
    "X_after = X_train_balanced[:, :3] # Variáveis independentes após o balanceamento\n",
    "y_after = y_train_balanced        # Variável dependente após o balanceamento\n",
    "\n",
    "# Gerar os gráficos\n",
    "plot_3d_before_after(X_before, y_before, X_after, y_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Análise\n",
    "\n",
    "#### Modelo Sem Balanceamento:\n",
    "- **Acurácia:** 81% \n",
    "- **Matriz de Confusão:**\n",
    "  - Classe 0: 1563 acertos (TN), 44 erros (FP).\n",
    "  - Classe 1: 57 acertos (TP), 336 erros (FN).\n",
    "- **Métricas Classe 1 (Minoritária):**\n",
    "  - **Precision:** 56% — Apenas 56% das previsões de saída (\\(Exited = 1\\)) estão corretas.\n",
    "  - **Recall:** 15% — Apenas 15% dos clientes que saíram foram corretamente identificados.\n",
    "  - **F1-Score:** 23% — Indica desempenho fraco para a classe minoritária.\n",
    "- **Conclusão:** O modelo é altamente enviesado para a classe majoritária (\\(Exited = 0\\)) devido ao desbalanceamento, com baixa capacidade de identificar a classe minoritária.\n",
    "\n",
    "#### Modelo com Balanceamento\n",
    "\n",
    "**Random Forest:**\n",
    "- **Acurácia:** 74%\n",
    "- **Matriz de Confusão:**\n",
    "  - Classe 0: 1282 acertos (TN), 311 erros (FP).\n",
    "  - Classe 1: 204 acertos (TP), 203 erros (FN).\n",
    "- **Métricas Classe 1:**\n",
    "  - **Precision:** 40%, **Recall:** 50%, **F1-Score:** 44%.\n",
    "- **AUC:** 0.6987 — Indica desempenho moderado para separar as classes.\n",
    "\n",
    "**Gradient Boosting:**\n",
    "- **Acurácia:** 75%\n",
    "- **Matriz de Confusão:**\n",
    "  - Classe 0: 1229 acertos (TN), 364 erros (FP).\n",
    "  - Classe 1: 273 acertos (TP), 134 erros (FN).\n",
    "- **Métricas Classe 1:**\n",
    "  - **Precision:** 43%, **Recall:** 67%, **F1-Score:** 52%.\n",
    "- **AUC:** 0.7909 — Melhor discriminação entre as classes em comparação com o Random Forest.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparação Geral\n",
    "\n",
    "- O modelo **sem balanceamento** é fortemente enviesado para a classe majoritária (\\(Exited = 0\\)), com **recall de apenas 15%** para a classe minoritária.\n",
    "- Após aplicar o balanceamento:\n",
    "  - **Gradient Boosting** apresenta melhor desempenho geral, especialmente na classe minoritária (\\(Exited = 1\\)), com **recall de 67%** e **AUC de 0.7909**.\n",
    "  - **Random Forest** tem desempenho inferior, com **recall de 50%** e **AUC de 0.6987**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Função para ajustar o threshold de classificação e avaliar o modelo\n",
    "def avaliar_modelo(model, X_test, y_test, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Avalia o desempenho do modelo ajustado com métricas como AUC, Curva ROC, precisão, sensibilidade e especificidade.\n",
    "    \"\"\"\n",
    "    # Obter probabilidades previstas\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # AUC e Curva ROC\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "\n",
    "    # Métricas de Avaliação\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)  # Sensibilidade\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Exibir Métricas\n",
    "    print(\"Métricas de Avaliação do Modelo:\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Precisão: {precision:.4f}\")\n",
    "    print(f\"Sensibilidade (Recall): {recall:.4f}\")\n",
    "    print(f\"Especificidade: {specificity:.4f}\")\n",
    "    print(f\"Acurácia: {accuracy:.4f}\")\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Plot da Curva ROC\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc:.4f})\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Curva ROC\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# 2. Otimização de Hiperparâmetros com GridSearchCV\n",
    "def otimizar_modelo(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Otimiza os hiperparâmetros do Gradient Boosting usando GridSearchCV.\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Melhores Hiperparâmetros:\", grid_search.best_params_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# 3. Ajustando o modelo com os melhores hiperparâmetros\n",
    "best_gb_model = otimizar_modelo(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# 4. Avaliando o modelo otimizado\n",
    "avaliar_modelo(best_gb_model, X_test_scaled, y_test, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Análise \n",
    "\n",
    "#### Explicação das Métricas\n",
    "\n",
    "1. **AUC e Curva ROC:**\n",
    "   - A **AUC (Área sob a Curva)** reflete a capacidade do modelo de discriminar entre clientes que saíram (\\(Exited = 1\\)) e os que ficaram (\\(Exited = 0\\)).\n",
    "   - Uma AUC maior significa que o modelo é melhor em distinguir corretamente entre as classes.\n",
    "\n",
    "2. **Precisão:**\n",
    "   - Mede a proporção de previsões corretas de saída (\\(Exited = 1\\)).\n",
    "   - Alta precisão indica que, quando o modelo prevê saída, ele está geralmente correto.\n",
    "\n",
    "3. **Sensibilidade (Recall):**\n",
    "   - Mede a capacidade do modelo de identificar corretamente os clientes que realmente saíram.\n",
    "   - É crucial para minimizar falsos negativos, garantindo que a maioria dos clientes propensos a sair seja detectada.\n",
    "\n",
    "4. **Especificidade:**\n",
    "   - Mede a capacidade do modelo de identificar corretamente os clientes que permaneceram (\\(Exited = 0\\)).\n",
    "   - Alta especificidade reduz falsos positivos, garantindo que clientes leais não sejam indevidamente classificados como propensos a sair.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusão\n",
    "\n",
    "O modelo **Gradient Boosting otimizado** oferece um equilíbrio entre precisão e recall, com **AUC de 0.7380** e **Recall da Classe 1 de 53%**, enquanto o **Gradient Boosting sem otimização** prioriza a detecção de clientes que saíram, com **AUC de 0.7909** e **Recall de 67%**. \n",
    "\n",
    "Ambos superam o **Random Forest** (AUC: 0.6987, Recall: 50%), sendo mais eficazes na discriminação entre as classes. A escolha do modelo depende do objetivo: equilíbrio geral ou maior recall para a classe minoritária.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
